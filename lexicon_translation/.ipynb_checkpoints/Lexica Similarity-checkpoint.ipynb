{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"../embeddings/CoNLL17/english/model.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexica Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "automatic_trans_lex = pd.read_csv(\"./lexicons_pons.csv\")\n",
    "automatic_trans_lex = automatic_trans_lex[automatic_trans_lex.lang == \"eng\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_trans_lex = pd.read_csv(\"./manually_translated_lexicons.csv\")\n",
    "manual_trans_lex.at[0,'lex']=\"modalization\"\n",
    "manual_trans_lex.at[1,'lex']=\"pressuposition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpqa = pd.read_csv(\"./lexica_similarity/automatic_x_mpqa/subjectivity_sense_annotations/subjectivity_sense_annotations/goldstandard.connl11/CoNNL11SenseAnnotations.txt\", \n",
    "                   sep=\" \", names=[\"word\",\"POS\",\"sense_key\",\"subj_level\"])\n",
    "\n",
    "mpqa = mpqa.word.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WMD between lexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_rand_lex(lex_name, lex, n_samples=5):\n",
    "    lex_len = len(lex.split())\n",
    "    \n",
    "    # generate random lexica\n",
    "    random_lex = [\" \".join(random.sample(model.wv.vocab.keys(), lex_len)) for i in range(n_samples)]\n",
    "    rand_lex_df = pd.DataFrame(random_lex, columns=[\"rand_words\"])\n",
    "    \n",
    "    # assign random label to each lexicon\n",
    "    lex = pd.DataFrame(np.tile([lex],n_samples), columns=[\"automatic_words\"])\n",
    "    lexica_df = pd.concat([lex,rand_lex_df], axis=1)\n",
    "    \n",
    "    # compute wmd between the lexica\n",
    "    wmd = lexica_df.apply(lambda x: model.wmdistance(x.automatic_words.split(), x.rand_words.split()), axis=1)\n",
    "    return(wmd.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate Most Similar lexicon \n",
    "def most_similar_lex(lex):\n",
    "    lex = lex.split()\n",
    "    most_similar_lex = []\n",
    "    for word in lex:\n",
    "        if word in model.vocab:\n",
    "            most_similar_word = model.most_similar(word, topn=1)[0][0] #get the word, not the entire vector\n",
    "            most_similar_lex.append(most_similar_word)\n",
    "    return(most_similar_lex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Most Similar lexicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_most_sim_lex = most_similar_lex(manual_trans_lex.words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_most_sim_lex = most_similar_lex(manual_trans_lex.words[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open output file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"lexica_dist_semantic_a.csv\", \"w\")\n",
    "f.write(\"lex,type_1,type_2,dist\"+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto x Random  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "mod_auto_rand_dist = generate_rand_lex(manual_trans_lex.lex[0], manual_trans_lex.words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"mod,auto,random,\"+str(mod_auto_rand_dist)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "pre_auto_rand_dist = generate_rand_lex(manual_trans_lex.lex[1], manual_trans_lex.words[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"pre,auto,random,\"+str(pre_auto_rand_dist)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto x Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auto_man_df = automatic_trans_lex.merge(manual_trans_lex, how = \"inner\", on=[\"lang\",\"lex\"])\n",
    "auto_man_dist = auto_man_df.apply(lambda x: model.wmdistance(x.words_x.split(), x.words_y.split()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.721713\n",
       "1    0.874691\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_man_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"mod,auto,manual,\"+str(auto_man_dist[0])+\"\\n\")\n",
    "f.write(\"pre,auto,manual,\"+str(auto_man_dist[1])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto x Most Similar to Manual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_auto_sim_dist = model.wmdistance(auto_man_df.words_x[0], mod_most_sim_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"mod,auto,sim_to_manual,\"+str(mod_auto_sim_dist)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_auto_sim_dist = model.wmdistance(auto_man_df.words_x[1], pre_most_sim_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"pre,auto,sim_to_manual,\"+str(pre_auto_sim_dist)+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual x Most Similar to Manual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_manual_sim_dist = model.wmdistance(auto_man_df.words_y[0], mod_most_sim_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"mod,manual,sim_to_manual,\"+str(mod_manual_sim_dist)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_manual_sim_dist = model.wmdistance(auto_man_df.words_y[1], pre_most_sim_lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write(\"pre,manual,sim_to_manual,\"+str(pre_manual_sim_dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto x MPQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_mpqa_dist = automatic_trans_lex.apply(lambda x: model.wmdistance(x.words.split(), mpqa), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2.652556\n",
       "6    2.555783\n",
       "7    2.656125\n",
       "8    2.841752\n",
       "9    2.562749\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mpqa_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sintatic Similarity between Lexica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def n_similar_items(a, b) -> tuple: \n",
    "    not_similar = [item for item in a if item not in b ]\n",
    "    n_diff = len(not_similar)\n",
    "    n_similar = len(a) - n_diff\n",
    "    return(n_similar, n_diff, not_similar)\n",
    "    \n",
    "sin_dist = auto_man_df.apply(lambda x: n_similar_items(x.words_x.split(), x.words_y.split()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"lexica_dist_sintatic_a.csv\", \"w\")\n",
    "f.write(\"lex,type_1,type_2,n_in_common,n_distinct,distinct_words\"+\"\\n\")\n",
    "f.write(\"mod,auto,man,\"+str(sin_dist[0][0])+\",\"+str(sin_dist[0][1])+\",\"+str(sin_dist[0][2])+\"\\n\")\n",
    "f.write(\"pre,auto,man,\"+str(sin_dist[1][0])+\",\"+str(sin_dist[1][1])+\",\"+str(sin_dist[1][2])+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WMD Change by word\n",
    "\n",
    "How WMD changes when we replace one word from the manual lexicon with a random word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0266016307853599\n",
      "0.03234575380657737\n"
     ]
    }
   ],
   "source": [
    "def generate_sim_word(word_idx, lex, model):\n",
    "    words = [model.most_similar(lex[idx], topn=1)[0][0] for idx in word_idx ]\n",
    "    return(words) #get the word, not the entire vector\n",
    "\n",
    "def generate_rand_word(model):\n",
    "    return(random.sample(model.wv.vocab.keys(), 2))\n",
    "\n",
    "def replace_and_compute_wmd(lex, idxs, words): # replace one word and compute WMD\n",
    "    #new_lex = lex.copy()\n",
    "    new_lex = list(lex)\n",
    "    for idx, word in zip(idxs, words):\n",
    "        new_lex[idx] = word\n",
    "    return(model.wmdistance(new_lex, lex))\n",
    "\n",
    "\n",
    "\n",
    "lex_dists = []\n",
    "for lex_idx in range(manual_trans_lex.shape[0]):\n",
    "    lex = manual_trans_lex.words[lex_idx].split()\n",
    "    rand_words_idx = random.sample(range(len(lex)), 1)\n",
    "    new_words = generate_rand_word(model)\n",
    "    #new_words = generate_sim_word(rand_words_idx, lex, model)\n",
    "    print(replace_and_compute_wmd(lex, rand_words_idx, new_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/allan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['162007..', 'cronberry']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(model.wv.vocab.keys(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "NUM_GENERATED_WORDS = 1\n",
    "\n",
    "def replace_and_compute_wmd(lex, idx, word): # replace one word and compute WMD\n",
    "    #new_lex = lex.copy()\n",
    "    new_lex = list(lex)\n",
    "    new_lex[idx] = word\n",
    "    return(model.wmdistance(new_lex, lex))\n",
    "\n",
    "def generate_rand_word(model):\n",
    "    return(random.sample(model.wv.vocab.keys(), 1)[0])\n",
    "\n",
    "def generate_sim_word(word, model):\n",
    "    return(model.most_similar(word, topn=NUM_GENERATED_WORDS)[0][0]) #get the word, not the entire vector\n",
    "\n",
    "lex_dists = []\n",
    "for lex_idx in range(manual_trans_lex.shape[0]): \n",
    "    lex = manual_trans_lex.words[lex_idx].split()\n",
    "    dists = []\n",
    "    for i, word in enumerate(lex):\n",
    "        if word in model.vocab:\n",
    "            new_word = generate_sim_word(word, model)\n",
    "            dist = [replace_and_compute_wmd(lex, idx, new_word) for idx, item in enumerate(lex)]\n",
    "            dists.append(dist)\n",
    "    lex_dists.append(dists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_agreement_level(n_words, one_word_dist, total_dist):\n",
    "    semantic_equal = n_words-(total_dist/one_word_dist)\n",
    "    agreement = (semantic_equal)/n_words\n",
    "    return(agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05631870773955988, 0.05511815628227828]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dists_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dists = [np.mean(dists) for dists in lex_dists]\n",
    "lex_sizes = auto_man_df.words_y.apply(lambda x: len(x.split()))\n",
    "\n",
    "semantic_agreement = semantic_agreement_level(lex_sizes, mean_dists, auto_man_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.762689\n",
       "1    0.706123\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.write(\"mod,manual,manual_with_single_word_change,\"+str(semantic_agreement[0])+\"\\n\")\n",
    "f.write(\"pre,manual,manual_with_single_word_change,\"+str(semantic_agreement[1]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
